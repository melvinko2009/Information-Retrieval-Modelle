{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9f71b6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Melvin\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\Melvin\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.QVLO2T66WEPI7JZ63PS3HMOHFEY472BC.gfortran-win_amd64.dll\n",
      "C:\\Users\\Melvin\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import spacy\n",
    "import operator\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import tensorflow as tf\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from rank_bm25 import *\n",
    "import fitz\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffb1e00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deutsche Stopwörter und Lemmatizer laden\n",
    "german_stopwords = stopwords.words('german')\n",
    "lemmatizer = spacy.load('de_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba7ce237",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No sentence-transformers model found with name C:\\Users\\Melvin/.cache\\torch\\sentence_transformers\\svalabs_bi-electra-ms-marco-german-uncased. Creating a new one with MEAN pooling.\n"
     ]
    }
   ],
   "source": [
    "#BERT Modell aus Huggingface laden\n",
    "bert_model = SentenceTransformer(\"svalabs/bi-electra-ms-marco-german-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1160b2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing der PDF-Texte\n",
    "def BERTpreprocessing(text):\n",
    "    sentenceDictionary = dict()\n",
    "    sentences = sent_tokenize(text, language='german')\n",
    "    for i in range(len(sentences)):\n",
    "        sentence = sentences[i]\n",
    "        cleanedSentence = cleanData(sentence)\n",
    "        sentenceVector = bert_model.encode(cleanedSentence)\n",
    "        sentenceDictionary[i] = [sentence,cleanedSentence,sentenceVector]\n",
    "    return sentenceDictionary\n",
    "\n",
    "# BM25 spezifisches Preprocessing\n",
    "def BMPreprocessing(text):\n",
    "    text = cleanData(text)\n",
    "    text = removeStopwords(text)\n",
    "    text = lemmatize(text)\n",
    "    text = word_tokenize(text, language='german')\n",
    "    return text\n",
    "\n",
    "def removeStopwords(text):\n",
    "    return ' '.join([word for word in text.split() if word not in german_stopwords])\n",
    "\n",
    "def lemmatize(text):\n",
    "    doc = lemmatizer(text)\n",
    "    return ' '.join([x.lemma_ for x in doc]) \n",
    "\n",
    "def cleanData(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub('[^a-zA-ZäöüÄÖÜß]', ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "932ea905",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Reusing dataset german_dpr (C:\\Users\\Melvin\\.cache\\huggingface\\datasets\\deepset___german_dpr)\\plain_text\\1.0.0\\35b77aa4815a72575b852f9aef779ed1d8dd1ea6d92a670545468c409ae88f06)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "913d6d2c35c54b618ed23ed22353c883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluierung des Modells anhand GermanDPR\n",
    "dataset = load_dataset(\"deepset/germandpr\")\n",
    "\n",
    "# Anfragen extrahieren\n",
    "queriesDPR = dataset['test']['question']\n",
    "\n",
    "# Kontextkorpus bilden\n",
    "contextsDPR = []\n",
    "for i in range(len(dataset['test'])):\n",
    "    contextsDPR.extend([dataset['test']['positive_ctxs'][i]['text'],\n",
    "                    dataset['test']['negative_ctxs'][i]['text'],\n",
    "                    dataset['test']['hard_negative_ctxs'][i]['text']])\n",
    "\n",
    "filteredContextsDPR = []\n",
    "for listItem in contextsDPR:\n",
    "    if len(listItem) == 0:\n",
    "        continue\n",
    "    elif len(listItem) == 1:\n",
    "        filteredContextsDPR.append(listItem[0])\n",
    "    else:\n",
    "        tempList = []\n",
    "        for item in listItem:\n",
    "            tempList.append(item)\n",
    "        filteredContextsDPR.extend(tempList)\n",
    "        \n",
    "# Deduplizieren\n",
    "filteredContextsDPR = list(set(filteredContextsDPR))\n",
    "\n",
    "# Richtige Antworten extrahieren\n",
    "correctPassagesDPR = []\n",
    "for i in range(len(dataset['test'])):\n",
    "    correctPassagesDPR.append(filteredContextsDPR.index(dataset['test']['positive_ctxs'][i]['text'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1d9f9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Daten für BM25 bereinigen\n",
    "BM25_EvaluationData, i = dict(), 0\n",
    "for text in filteredContextsDPR:\n",
    "    BM25_EvaluationData[i] = BMPreprocessing(text)\n",
    "    i+=1\n",
    "\n",
    "#Daten für BERT bereinigen\n",
    "BERT_EvaluationData, i = dict(), 0\n",
    "for text in filteredContextsDPR:\n",
    "    BERT_EvaluationData[i] = BERTpreprocessing(text)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92d6bc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BM25 Modell initialisieren\n",
    "bm25 = BM25Okapi(list(BM25_EvaluationData.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "184cc68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kosinus-Ähnlichkeit\n",
    "def cosineSimilarity(vector1, vector2):\n",
    "    return np.dot(vector1,vector2) / (np.linalg.norm(vector1) * np.linalg.norm(vector2))\n",
    "\n",
    "#BERT Voraussage\n",
    "def get_BERT_Prediction_Eval(query, docIds=None):\n",
    "    queryEncoded = bert_model.encode(query)\n",
    "    bertScores = dict()\n",
    "    \n",
    "    for docID, sentenceDictionary in BERT_EvaluationData.items():\n",
    "        if docIds != None:\n",
    "            if docID not in docIds:\n",
    "                continue\n",
    "        scores,docBestSentences = [], dict()\n",
    "        for sentID, values in sentenceDictionary.items():\n",
    "            similarity = cosineSimilarity(queryEncoded,values[2])\n",
    "            docBestSentences[sentID] = similarity\n",
    "            scores.append(similarity)\n",
    "        docBestSentences = dict(sorted(docBestSentences.items(), key=operator.itemgetter(1),reverse=True))\n",
    "        docSimilarity = np.mean(sorted(scores,reverse=True)[:5])\n",
    "        bertScores[docID] = np.mean(sorted(scores,reverse=True)[:5])\n",
    "    return dict(sorted(bertScores.items(), key=operator.itemgetter(1),reverse=True))\n",
    "\n",
    "#BM25 Voraussage\n",
    "def get_BM25_Prediction_Eval(query):\n",
    "    query= cleanData(query)\n",
    "    query = removeStopwords(query)\n",
    "    query = lemmatize(query)\n",
    "    query = word_tokenize(query.lower(), language='german')\n",
    "    \n",
    "    doc_scores = bm25.get_scores(query)\n",
    "    bm25Scores = dict()\n",
    "    for i in range(len(doc_scores)):\n",
    "        #if doc_scores[i] != 0:\n",
    "        bm25Scores[i] = doc_scores[i]\n",
    "    return dict(sorted(bm25Scores.items(), key=operator.itemgetter(1),reverse=True))\n",
    "\n",
    "# Kombinierte Voraussage mit Theta als Schwellwert und k1 als Gewichtubngsparameter\n",
    "def get_Combined_Prediction_Eval(query,theta,k1):\n",
    "    bertScores = get_BERT_Prediction_Eval(query)\n",
    "    bm25Scores = get_BM25_Prediction_Eval(query)\n",
    "    combinedScores = dict()\n",
    "    \n",
    "    if len(bm25Scores) == 0 and len(bertScores) == 0:\n",
    "        return dict()\n",
    "    if len(bm25Scores) == 0:\n",
    "         return bertScores\n",
    "    if len(bertScores) == 0:\n",
    "        return bm25Scores\n",
    "    \n",
    "    if len(bm25Scores) == 1:\n",
    "        for docId, score in bm25Scores.items():\n",
    "            bm25Scores[docId] = 1\n",
    "    else:\n",
    "        minBM25,maxBM25 = np.min(list(bm25Scores.values())), np.max(list(bm25Scores.values())) \n",
    "        \n",
    "        #BM25 normalisieren\n",
    "        for docId, score in bm25Scores.items():\n",
    "            bm25Scores[docId] = (score - minBM25) / (maxBM25 - minBM25)\n",
    "            \n",
    "    if len(bertScores) == 1:\n",
    "        for docId, score in bertScores.items():\n",
    "            bertScores[docId] = 1\n",
    "    else:\n",
    "        minBert,maxBert = np.min(list(bertScores.values())), np.max(list(bertScores.values())) \n",
    "        \n",
    "       #BERT normalisieren\n",
    "        for docId, score in bertScores.items():\n",
    "            bertScores[docId] = (score - minBert) / (maxBert - minBert)\n",
    "        \n",
    "    #Kombinieren mit k1 Gewichtung\n",
    "    for docId in BM25_EvaluationData.keys():\n",
    "        bm25Score, bertScore = 0,0\n",
    "        if docId in bm25Scores:\n",
    "            bm25Score = bm25Scores[docId]  \n",
    "        if docId in bertScores:\n",
    "            bertScore = bertScores[docId]\n",
    "        combined = k1 * bertScore + (1-k1)* bm25Score \n",
    "        if combined > theta:\n",
    "            combinedScores[docId] = k1 * bertScore + (1-k1)* bm25Score \n",
    "    resultScores = dict(sorted(combinedScores.items(), key=operator.itemgetter(1),reverse=True))\n",
    "    return resultScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4bc02bc2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Melvin\\AppData\\Local\\Temp/ipykernel_23176/619801173.py:59: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  bm25Scores[docId] = (score - minBM25) / (maxBM25 - minBM25)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Methode zur Erzeugung aller Voraussagen\n",
    "def getPredictions():\n",
    "    predicted = []\n",
    "    relevant = []\n",
    "    for i in range(len(queriesDPR)):\n",
    "        prediction = get_Combined_Prediction_Eval(queriesDPR[i],0,0.7)\n",
    "        if len(prediction) != 0:\n",
    "            predicted.append(list(prediction.keys()))\n",
    "            relevant.append(correctPassagesDPR[i]) \n",
    "    return predicted, relevant\n",
    "\n",
    "predicted, relevant = getPredictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecb1a426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall@k\n",
    "def recallEval(predicted, relevant,k):\n",
    "    count = 0\n",
    "    for i in range(k):\n",
    "        if predicted[i] == relevant:\n",
    "            count +=1\n",
    "    return count \n",
    "\n",
    "# Average Recall@k\n",
    "def averageRecall(predicted, relevant,k=10):\n",
    "    averageRecall = 0\n",
    "    for i in range(len(predicted)):\n",
    "        averageRecall += recallEval(predicted[i],relevant[i],k)\n",
    "    return averageRecall / len(relevant)\n",
    "\n",
    "\n",
    "# Exact Matches (first is hit)\n",
    "def EM(predicted, relevant):\n",
    "    em = 0\n",
    "    for i in range(len(predicted)):\n",
    "        if predicted[i][0] == relevant[i]:\n",
    "            em+=1\n",
    "    return em /len(relevant)\n",
    "\n",
    "#Precision@k\n",
    "def precisionEval(predicted, truth, k):\n",
    "    summe,count = 0, 0\n",
    "    for i in range(k+1):\n",
    "        if int(predicted[i]) == truth:\n",
    "            count+=1\n",
    "    summe+= count/ (i+1)\n",
    "    return summe    \n",
    "\n",
    "# AP@k\n",
    "def average_precisionEval(predicted,relevant):\n",
    "    averageSum = 0\n",
    "    scores = dict()\n",
    "    for i in range(0,len(predicted)):\n",
    "        summe = 0  \n",
    "        if int(predicted[i]) == relevant:\n",
    "            summe+= precisionEval(predicted, relevant, i)\n",
    "        averageSum += summe\n",
    "    return averageSum\n",
    "\n",
    "#MAP\n",
    "def mean_average_precisionEval(predicted,relevant):\n",
    "    summe = 0\n",
    "    for i in range(0,len(predicted)):\n",
    "        summe += average_precisionEval(predicted[i],relevant[i])\n",
    "    return summe/len(predicted)\n",
    "\n",
    "#RR\n",
    "def reciprocal_rankEval(predicted,relevant):\n",
    "    for i in range(0, len(predicted)):\n",
    "        if int(predicted[i]) == relevant:\n",
    "            return 1/(i+1)\n",
    "    return 0\n",
    "\n",
    "#MRR\n",
    "def mean_reciprocal_rankEval(predicted,relevant):\n",
    "    summe = 0\n",
    "    for i in range(0,len(predicted)):\n",
    "        rec_rank = reciprocal_rankEval(predicted[i],relevant[i])\n",
    "        summe += rec_rank\n",
    "    return summe/len(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aadd647d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3583984375, 0.9296875)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getMetrics(predicted, relevant):\n",
    "    em = EM(predicted, relevant)\n",
    "    ar = averageRecall(predicted, relevant,10)\n",
    "    return em, ar\n",
    "getMetrics(predicted, relevant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7fb3b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
